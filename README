# Transformers

This repository is dedicated to transformers. It covers core concepts such as attention and implements transformer models from scratch.

## Attention

The "Attention" folder contains an explanation and the implementation of the attention mechanism.

## Future Updates

More content will be added soon.

## Setup

To set up the environment, follow these steps:

1. Create the conda environment using the provided YAML file:


## Setup
```
conda env create -f conda.yaml
conda activate transformers-env
transformers-env/Scripts/Activate
```

