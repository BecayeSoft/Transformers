{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Normalization\n",
    "\n",
    "The activation of neurons is typically a wide range of values.\n",
    "Noramlization maps the value in a small range typically centered around zero. This allows the training to be more stable. With small values, we take big steps to update the neural network.\n",
    "\n",
    "![Alt text](../imgs/layer-normalization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply layer normalization, we follow these steps:\n",
    "\n",
    "1. Normalize the inputs\n",
    "$$\n",
    "\\hat{x_i} = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}  \\  \\text { normalization }  \\\\\n",
    "$$\n",
    "\n",
    "2. Scale and shift\n",
    "$$\n",
    "{y_i} = \\gamma \\hat{x_i} + \\beta   \\    \\text {scale and shift }   \\\\\n",
    "$$\n",
    "\n",
    "\n",
    "Where $\\mu$ is the mean of the inputs and $\\sigma^2$ is the variance of the inputs:\n",
    "$$\n",
    "\\mu = \\frac{1}{m} \\sum_{i=1}^{m} x_i  \\   \\text { batch mean } \\\\\n",
    "\\sigma^2 = \\frac{1}{m} \\sum_{i=1}^{m} (x_i - \\mu)^2  \\   \\text { batch standard deviation } \\\\\n",
    "$$\n",
    "\n",
    "$\\epsilon$ is a small number to avoid division by zero, $\\gamma$ is the scale parameter, and $\\beta$ is the shift parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = inputs\n",
    "# m = X.size()[-1]            # the last dimesnion is \"3\", the number of elements in the tensor\n",
    "# epsilon = 1e-5\n",
    "\n",
    "# # Mean\n",
    "# dims = (-1, -2)   # or -1\n",
    "# mu = (1 / m) * torch.sum(X, dim=dims, keepdim=True)\n",
    "\n",
    "# # Standard Deviation\n",
    "# sigma2 = (1 / m) * torch.sum((X - mu) ** 2, dim=dims, keepdim=True)\n",
    "\n",
    "# # Normalization\n",
    "# X_norm = (X - mu) / torch.sqrt(sigma2 + epsilon) \n",
    "\n",
    "# # Scale and Shift\n",
    "# Y = gamma * X_norm + beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializng the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.Tensor([ [ [0.2, 0.1, 0.3], [0.5, 0.1, 0.1] ] ])\n",
    "batch_size, sequence_size, embedding_size = inputs.size()\n",
    "inputs = inputs.reshape(sequence_size, batch_size, embedding_size)\n",
    "\n",
    "print(\"Input shape:\", inputs.size())\n",
    "sequence_size, batch_size, embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 is the number of inputs (words), 1 is the batch and 3 is the embedding dimension of each word.\n",
    "\n",
    "### Parameters of Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter shape: torch.Size([1, 3])\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0., 0., 0.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "parameter_shape = inputs.size()[-2:]\n",
    "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "beta = nn.Parameter(torch.zeros(parameter_shape))\n",
    "\n",
    "print(\"Parameter shape:\", parameter_shape)\n",
    "print(gamma)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Setting the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can dynamically get the last two dimensions of the tensor\n",
    "# dims = [-(i+1) for i in range(len(parameter_shape))]\n",
    "# dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (-2, -1)     # -1 also works but I do know the potential issues yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2000, 0.1000, 0.3000]],\n",
       "\n",
       "        [[0.5000, 0.1000, 0.1000]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = inputs.mean(dims, keepdim=True)\n",
    "# print(mean.size()) \n",
    "# mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more detailed way to calculate the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2000]],\n",
       "\n",
       "        [[0.2333]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = inputs\n",
    "m = X.size()[-1]\n",
    "mu = (1 / m) * torch.sum(X, dim=-1, keepdim=True)\n",
    "\n",
    "print(mu.size()) \n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation\n",
    "\n",
    "We add epsilon to the standard deviation to avoid dividing by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance = (\n",
    "#     ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "# )\n",
    "# variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more detailed way to calculate the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0067]],\n",
       "\n",
       "        [[0.0356]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Deviation\n",
    "sigma2 = (1 / m) * torch.sum( (X - mu) ** 2, dim=dims, keepdim=True )\n",
    "sigma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std = epsilon + torch.sqrt(sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0817]],\n",
       "\n",
       "        [[0.1886]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 1e-5\n",
    "denominator = torch.sqrt(sigma2 + epsilon)\n",
    "denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 3]), torch.Size([2, 1, 1]), torch.Size([2, 1, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = (inputs - mean) / std\n",
    "X.shape, mu.shape, denominator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8236e-07, -1.2238e+00,  1.2238e+00]],\n",
       "\n",
       "        [[ 1.4140e+00, -7.0701e-01, -7.0701e-01]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm = (X - mu) / denominator\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = gamma * y + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8236e-07, -1.2238e+00,  1.2238e+00]],\n",
       "\n",
       "        [[ 1.4140e+00, -7.0701e-01, -7.0701e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = gamma * X_norm + beta\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8236e-07, -1.2238e+00,  1.2238e+00]],\n",
       "\n",
       "        [[ 1.4140e+00, -7.0701e-01, -7.0701e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.LayerNormalization import LayerNormalization\n",
    "\n",
    "inputs = torch.tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
    "batch_size, seq_len, embedding_dim = inputs.size()\n",
    "inputs = inputs.reshape(seq_len, batch_size, embedding_dim)\n",
    "\n",
    "ln = LayerNormalization(\n",
    "    sequence_length=seq_len, batch_size=batch_size, embedding_dim=embedding_dim\n",
    ")\n",
    "\n",
    "ln.forward(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
