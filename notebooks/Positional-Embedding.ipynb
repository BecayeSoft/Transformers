{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Embedding\n",
    "\n",
    "Unlike RNNs, transformers take all the input at once, not sequentially. So, we don't know the order of the words, which why we use \"Positional Embedding\".\n",
    "\n",
    "Why do we use sine and cosine?\n",
    "1. Periodicity: a word can pay attention to let's say 5 word after it, then 10, 15, 20, ...\n",
    "2. Constrained value: the value of the embedding is between -1 and 1, which is good for the attention mechanism.\n",
    "3. Easy to extrapolate: deterministic function. Even if we haven't seen a word, we can still predict its embedding.\n",
    "\n",
    "![Positional Encoding](../imgs/positional-encoding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\text PE_{(pos, 2i)} &=\\operatorname{sin} \\left(\\frac{pos} {10000^{2i / d_{model}}} \\right) \\\\\n",
    "\\text PE_{(pos, 2i+1)} &=\\operatorname{cos} \\left(\\frac{pos} {10000^{2i / d_{model}}} \\right) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Simplified formula:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text PE_{(pos, i)} &=\\operatorname{sin} \\left(\\frac{pos} {10000^{i / d_{model}}} \\right) when \\ i \\ is \\ even \\\\\n",
    "\\text PE_{(pos, i)} &=\\operatorname{cos} \\left(\\frac{pos} {10000^{i-1 / d_{model}}} \\right) when \\ i \\ is \\ odd \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $pos$ is the position and $i$ is the embedding dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "max_sequence_length = 10    # Much bigger in reality (thousands)\n",
    "d_model = 6                 # Embedding dim: Original is 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 2., 4.]), tensor([  1.0000,  21.5443, 464.1590]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enven_i = torch.arange(0, d_model, 2).float()\n",
    "enven_denominator = 10000 ** (enven_i / d_model)\n",
    "enven_i, enven_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 3., 5.]), tensor([  1.0000,  21.5443, 464.1590]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_i = torch.arange(1, d_model, 2).float()\n",
    "odd_denominator = torch.pow(10000, ((odd_i-1) / d_model))\n",
    "odd_i, odd_denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even and odd denominator are the same because the odd_i is one more than even_i, and we substract 1 in the denimator, so the result becomes the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator = odd_denominator\n",
    "position = torch.arange(0, max_sequence_length)\n",
    "print(position.shape)\n",
    "# Reshape the position so that we have 1 position for each word\n",
    "position = position.reshape(-1, 1)      # -1 == max_sequence_length\n",
    "print(position.shape)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "position has a shape of (10, 1) and denominator has a shape of (1, 3), so the result has a shape of (10, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 4.6416e-02, 2.1544e-03],\n",
       "        [2.0000e+00, 9.2832e-02, 4.3089e-03],\n",
       "        [3.0000e+00, 1.3925e-01, 6.4633e-03],\n",
       "        [4.0000e+00, 1.8566e-01, 8.6177e-03],\n",
       "        [5.0000e+00, 2.3208e-01, 1.0772e-02],\n",
       "        [6.0000e+00, 2.7850e-01, 1.2927e-02],\n",
       "        [7.0000e+00, 3.2491e-01, 1.5081e-02],\n",
       "        [8.0000e+00, 3.7133e-01, 1.7235e-02],\n",
       "        [9.0000e+00, 4.1774e-01, 1.9390e-02]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8415,  0.0464,  0.0022],\n",
       "         [ 0.9093,  0.0927,  0.0043],\n",
       "         [ 0.1411,  0.1388,  0.0065],\n",
       "         [-0.7568,  0.1846,  0.0086],\n",
       "         [-0.9589,  0.2300,  0.0108],\n",
       "         [-0.2794,  0.2749,  0.0129],\n",
       "         [ 0.6570,  0.3192,  0.0151],\n",
       "         [ 0.9894,  0.3629,  0.0172],\n",
       "         [ 0.4121,  0.4057,  0.0194]]),\n",
       " tensor([[ 1.0000,  1.0000,  1.0000],\n",
       "         [ 0.5403,  0.9989,  1.0000],\n",
       "         [-0.4161,  0.9957,  1.0000],\n",
       "         [-0.9900,  0.9903,  1.0000],\n",
       "         [-0.6536,  0.9828,  1.0000],\n",
       "         [ 0.2837,  0.9732,  0.9999],\n",
       "         [ 0.9602,  0.9615,  0.9999],\n",
       "         [ 0.7539,  0.9477,  0.9999],\n",
       "         [-0.1455,  0.9318,  0.9999],\n",
       "         [-0.9111,  0.9140,  0.9998]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos_embedding = torch.sin(position / (10000 ** (enven_i / d_model)))\n",
    "even_PE = torch.sin(position / denominator)\n",
    "odd_PE = torch.cos(position / denominator)\n",
    "even_PE, odd_PE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the even_i is for even number (0, 2, ...) and the odd_i is for odd number (1, 3, ...). So to get the complete positional embedding, we need to concatenate the even_i and odd_i one after the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3]), torch.Size([10, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_PE.shape, odd_PE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  1.0000],\n",
       "         [ 0.0000,  1.0000],\n",
       "         [ 0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.8415,  0.5403],\n",
       "         [ 0.0464,  0.9989],\n",
       "         [ 0.0022,  1.0000]],\n",
       "\n",
       "        [[ 0.9093, -0.4161],\n",
       "         [ 0.0927,  0.9957],\n",
       "         [ 0.0043,  1.0000]],\n",
       "\n",
       "        [[ 0.1411, -0.9900],\n",
       "         [ 0.1388,  0.9903],\n",
       "         [ 0.0065,  1.0000]],\n",
       "\n",
       "        [[-0.7568, -0.6536],\n",
       "         [ 0.1846,  0.9828],\n",
       "         [ 0.0086,  1.0000]],\n",
       "\n",
       "        [[-0.9589,  0.2837],\n",
       "         [ 0.2300,  0.9732],\n",
       "         [ 0.0108,  0.9999]],\n",
       "\n",
       "        [[-0.2794,  0.9602],\n",
       "         [ 0.2749,  0.9615],\n",
       "         [ 0.0129,  0.9999]],\n",
       "\n",
       "        [[ 0.6570,  0.7539],\n",
       "         [ 0.3192,  0.9477],\n",
       "         [ 0.0151,  0.9999]],\n",
       "\n",
       "        [[ 0.9894, -0.1455],\n",
       "         [ 0.3629,  0.9318],\n",
       "         [ 0.0172,  0.9999]],\n",
       "\n",
       "        [[ 0.4121, -0.9111],\n",
       "         [ 0.4057,  0.9140],\n",
       "         [ 0.0194,  0.9998]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = torch.stack((even_PE, odd_PE), dim=2)\n",
    "print(stacked.shape)\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we flatten the array the array on the first dimension, so that we get a shape of (10, 6) representing the 10 words and the embedding dimension of 6.<br>\n",
    "This complete the concatenation of the odd and even positional embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
       "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
       "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
       "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
       "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
       "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
       "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
       "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "print(PE.shape)\n",
    "PE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00],\n",
       "        [-9.9749e-01, -7.0741e-02,  4.6416e-04,  1.0000e+00,  4.6416e-08,\n",
       "          1.0000e+00,  4.6416e-12,  1.0000e+00,  4.6416e-16,  1.0000e+00,\n",
       "          4.6416e-20,  1.0000e+00],\n",
       "        [ 1.4113e-01, -9.8999e-01,  9.2832e-04,  1.0000e+00,  9.2832e-08,\n",
       "          1.0000e+00,  9.2832e-12,  1.0000e+00,  9.2832e-16,  1.0000e+00,\n",
       "          9.2832e-20,  1.0000e+00],\n",
       "        [ 9.7753e-01,  2.1081e-01,  1.3925e-03,  1.0000e+00,  1.3925e-07,\n",
       "          1.0000e+00,  1.3925e-11,  1.0000e+00,  1.3925e-15,  1.0000e+00,\n",
       "          1.3925e-19,  1.0000e+00],\n",
       "        [-2.7943e-01,  9.6017e-01,  1.8566e-03,  1.0000e+00,  1.8566e-07,\n",
       "          1.0000e+00,  1.8566e-11,  1.0000e+00,  1.8566e-15,  1.0000e+00,\n",
       "          1.8566e-19,  1.0000e+00],\n",
       "        [-9.3799e-01, -3.4665e-01,  2.3208e-03,  1.0000e+00,  2.3208e-07,\n",
       "          1.0000e+00,  2.3208e-11,  1.0000e+00,  2.3208e-15,  1.0000e+00,\n",
       "          2.3208e-19,  1.0000e+00],\n",
       "        [ 4.1214e-01, -9.1112e-01,  2.7850e-03,  1.0000e+00,  2.7850e-07,\n",
       "          1.0000e+00,  2.7850e-11,  1.0000e+00,  2.7850e-15,  1.0000e+00,\n",
       "          2.7849e-19,  1.0000e+00],\n",
       "        [ 8.7968e-01,  4.7556e-01,  3.2491e-03,  9.9999e-01,  3.2491e-07,\n",
       "          1.0000e+00,  3.2491e-11,  1.0000e+00,  3.2491e-15,  1.0000e+00,\n",
       "          3.2491e-19,  1.0000e+00],\n",
       "        [-5.3660e-01,  8.4384e-01,  3.7133e-03,  9.9999e-01,  3.7133e-07,\n",
       "          1.0000e+00,  3.7133e-11,  1.0000e+00,  3.7133e-15,  1.0000e+00,\n",
       "          3.7133e-19,  1.0000e+00],\n",
       "        [-8.0376e-01, -5.9495e-01,  4.1774e-03,  9.9999e-01,  4.1774e-07,\n",
       "          1.0000e+00,  4.1774e-11,  1.0000e+00,  4.1774e-15,  1.0000e+00,\n",
       "          4.1774e-19,  1.0000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.PostionalEmbedding import PositionalEmbedding\n",
    "\n",
    "pe = PositionalEmbedding(embedding_dim=6, max_sequence_length=10)\n",
    "pe.forward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
