{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-head attention\n",
    "\n",
    "The multi-head attention is a componet of the transfoermer. It is composed of multiple \"Scaled Dot-product attention\". \n",
    "\n",
    "<div style=\"display:flex; justify-content:space-between; max-width:850px\">\n",
    "    <img src=\"imgs/transformer.png\" width=\"400\"/>\n",
    "    <img src=\"imgs/multi-head-attention.png\" width=\"400\" height=\"350\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of the input sequence\n",
    "sequence_length = 4\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# Input dimension of the vectors that go into the attention unit\n",
    "input_dim = 512\n",
    "\n",
    "# Output dimension of the attention unit\n",
    "attention_output_dim = 512\n",
    "\n",
    "# Since we do not calculate the positional encodings here,\n",
    "# X represent the values (input + position embedding) \n",
    "# that are gonna be fed directly to the transformer\n",
    "X = torch.randn(batch_size, sequence_length, input_dim)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=1536, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer_in = nn.Linear(\n",
    "    in_features=input_dim, out_features=attention_output_dim * 3     # 3 because we have 3 vectors Q, K, V\n",
    ")\n",
    "\n",
    "print(linear_layer_in)\n",
    "\n",
    "QKV = linear_layer_in(X)\n",
    "QKV.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the tensor values distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'QKV distribution')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_val = torch.histc(QKV, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "plt.bar(x_val, y_val, align='center', color=['forestgreen'])\n",
    "plt.title('QKV distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scaled Dot-Product Attention\n",
    "\n",
    "We create an attention module with:\n",
    "- 8 heads\n",
    "- A head dimension of 64 (our input dimension is 512 / 8 heads = 64).\n",
    "-  A sequence length of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 heads\n",
      "Head dimension: 64      # Each word will be represented as a 64 dimensional vector in a head.\n",
      "QKV.shape: torch.Size([1, 8, 4, 192])\n"
     ]
    }
   ],
   "source": [
    "n_heads = 8\n",
    "head_dim = attention_output_dim // n_heads\n",
    "\n",
    "print(f\"{n_heads} heads\")\n",
    "print(f\"Head dimension: {head_dim}      # Each word will be represented as a 64 dimensional vector in a head.\")\n",
    "\n",
    "QKV = QKV.reshape(\n",
    "    # batch_size, sequence_length, n_heads, head_dim * 3\n",
    "    batch_size, n_heads, sequence_length, head_dim * 3\n",
    ")\n",
    "# For easier parallel processing, put the head before\n",
    "# QKV.permute(0, 2, 1, 3).shape\n",
    "\n",
    "print(f\"QKV.shape: {QKV.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Query, Key, and Value vectors**\n",
    "\n",
    "We can now extract the Query, Key and Value vectors from `QKV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to see how to extract values on a particular dimension from a tensor\n",
    "# t = torch.rand([2, 2, 3])\n",
    "# print(t)\n",
    "# t.chunk(3, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QKV.shape: torch.Size([1, 8, 4, 192])\n",
      "Q, K, V shapes: (torch.Size([1, 8, 4, 64]), torch.Size([1, 8, 4, 64]), torch.Size([1, 8, 4, 64]))\n",
      "N heads: 8\n",
      "Sequence Length: 4\n",
      "Head dimension: 64\n"
     ]
    }
   ],
   "source": [
    "# Extract Q, K, V by breaking the last \n",
    "# dimension of QKV into 3 chunks\n",
    "Q, K, V = QKV.chunk(3, dim=-1)\n",
    "\n",
    "print(f\"QKV.shape: {QKV.shape}\")\n",
    "print(f\"Q, K, V shapes: {Q.shape, K.shape, V.shape}\")\n",
    "print(f\"N heads: {Q.shape[1]}\")\n",
    "print(f\"Sequence Length: {Q.shape[2]}\")\n",
    "print(f\"Head dimension: {Q.shape[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the self-attention\n",
    "\n",
    "> Matmul > Scale > Mask > Softmax > Matmul\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text { Attention }(Q, K, V) &=\\operatorname{softmax} \\left(\\frac{Q. K^{T}} {\\sqrt{d_{k}}} + M \\right) V \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matmul**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: torch.Size([1, 8, 4, 64])\n",
      "K Transposed (Wrong): torch.Size([64, 4, 8, 1])\n",
      "K Transposed: torch.Size([1, 8, 64, 4])\n",
      "K Transposed: torch.Size([1, 8, 64, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"K: {K.shape}\")\n",
    "# Not suitable for tensors (Swap all dimensions)\n",
    "print(f\"K Transposed (Wrong): {K.T.shape}\")\n",
    "# Swap the last two dimension (Same result, dimensions are the same)\n",
    "print(f\"K Transposed: {K.transpose(-2, -1).shape}\")\n",
    "print(f\"K Transposed: {K.transpose(-1, -2).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_dim = Q.shape[-1]     # head dim, Q last dim\n",
    "\n",
    "scaled = torch.matmul(\n",
    "    Q, K.transpose(-2, -1)\n",
    ") / np.sqrt(head_dim)\n",
    "\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Masking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.shape, -torch.inf)\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0][0]  # mask of the first head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2027,    -inf,    -inf,    -inf],\n",
       "        [-0.4861, -0.1218,    -inf,    -inf],\n",
       "        [ 0.0859, -0.2417,  0.2456,    -inf],\n",
       "        [ 0.1029, -0.9370, -0.0714,  0.1687]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_scaled = scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = F.softmax(masked_scaled, dim=-1)\n",
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**\n",
    "\n",
    "The ideas is to obtain new values vector that are much more context aware than the original values vector.\n",
    "\n",
    "Now we multiply the softmax scores with the values vector to get the new values.\n",
    "\n",
    "The shape [1, 8, 4, 64] means:\n",
    "- 8 heads\n",
    "- Each head takes in 4 words\n",
    "- Each word is encoded as a 64 dimensionnal vector in a single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: torch.Size([1, 8, 4, 4])\n",
      "V: torch.Size([1, 8, 4, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Attention weights:\", attention_weights.shape)\n",
    "print(f\"V:\", V.shape)\n",
    "\n",
    "attention_output  = torch.matmul(attention_weights, V)\n",
    "attention_output .shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Concatenation\n",
    "\n",
    "Now we concatenate the outputs of the 8 heads to get a single vector of shape [1, 4, 512]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output = attention_output.reshape(\n",
    "    batch_size, sequence_length, n_heads*head_dim\n",
    ")\n",
    "\n",
    "attention_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linear\n",
    "\n",
    "We pass the output to a dense layer so that the heads can communicate with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer_out = nn.Linear(attention_output_dim, attention_output_dim)\n",
    "linear_layer_out\n",
    "\n",
    "out = linear_layer_out(attention_output)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Attention is all you need, Ashish Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)\n",
    "- [CodeEmporium - Multi Head Attention in Transformer Neural Networks with Code!](https://www.youtube.com/watch?v=HQn1QKQYXVg&list=PLTl9hO2Oobd97qfWC40gOSU8C0iu0m2l4&index=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
